---
output:
  pdf_document:
    citation_package: natbib
    toc: no
editor_options:
  chunk_output_type: console
header-includes:
  - \pagenumbering{gobble}
  - \usepackage[round]{natbib}
  - \renewcommand{\bibsection}{}
fontsize: 12pt
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```
\begin{center}
\vspace*{75pt}
\Huge \textbf{Who are the financial profiteers of war?} \\
\vspace{50pt}
\Large University of Applied Sciences Lucerne \\[10pt]
\Large Master of Science in Applied Information and Data Science \\[10pt]
\Large Time Series in Finance (TSA01) \\[10pt]
\vspace{50pt}
\Large Authors: Mich√®le Gerber and Damien Grossniklaus \\
\Large Date of Submission: 22. December 2023 \\
\end{center}



\newpage
```{=latex}
\setcounter{tocdepth}{4}
\tableofcontents
```
\newpage
\pagenumbering{arabic}

```{r, eval=FALSE, echo=FALSE, results=FALSE}
tinytex::reinstall_tinytex()
install.packages("readr")
install.packages("colorspace")
install.packages("vctrs")
install.packages("gtrendsR")
```


```{r, echo=FALSE, results=FALSE, message=FALSE, include=FALSE}
library(quantmod)
library(tseries)
#library(readr) #Disable in order to Google trends package to work
library(gtrendsR)
library(lubridate)
library(ggplot2)
library(zoo)
library(dplyr)
library(tidyr)
library(vars)
```


## 1. Introduction

With recent outbreaks of war (e.g., in Israel and Ukraine), the question arises of how stock markets react to this and if there are sectors that profit from such crises. Specifically, this case study examines whether several indices from specific economic sectors perform well in situations of crisis. The following two indices are included in the analysis:

* **XLI**: Industrial Select Sector
* **XLB**: Materials Select Sector

Essentially, our research question is the following: *Who are the financial profiteers of war?*. To answer this question, the performance of the sector-specific indices should be compared to an overall crisis measure. As an overall crisis measure, the Google Trend data for the search word *"war"* is used. We postulate, that an increased search for this term points to a higher crisis. So in conclusion, we want to examine if there are positive correlations between our crisis measure and stock market profits in the different indices. 

## 2. Methods and Hypotheses

The method we will use is vector autoregression (VAR). This allows us to measure the influence of our crisis measure on the performance of the different indices. For each index, we will calculate a separate model. Furthermore, to address potential spurious correlations, we include inflation as a control variable in our models. To test for a causal relationship between the crisis measure and the indices, a "*Granger Causality Test*" will be conducted for every index. 

Before a VAR and causality test can be carried out, the different time series (indices, crisis measures, and inflation) have to be imported, cleaned and pre-processed. Specifically, potential seasonal effects and trends in each time series have to be identified and adjusted for to achieve stationarity. A stationary time series is characterized by a stabilized mean and variance over time, and will ultimately allow more reliable and accurate modeling [@AnkenbrandBieri]. To test the stationarity of a time series, the "*Augmented Dickey-Fuller Test*" will be carried out. Furthermore, the stationarity is checked by visualizing the time series. If a time series is non-stationary, lagged differences will be calculated. Lastly, to get continuous growth rates, the time series will first be logarithmized before applying the difference.

The two chosen indices both encompass companies that could profit from war. The industrials select sector has, among others, defense companies and the materials select sector steel production companies in it. Our hypothesis, therefore, is that these two sectors are likely to profit from war and that our crisis measure will have a positive influence on these indices. In an analysis done on the performance of different sectors during World War II, these sectors were not among the best performing sectors. Instead, printing & publishing and beer & liquor performed best [@Whichsec96:online]. Nevertheless, we want to check if our assumption holds true in today's economy under the current crisis.

## 3. Data Sources

```{r, include=FALSE}
### Import Time Series Data

# Ticker Data
ticker_data <- NULL
tickers_index <- c("XLI", "XLB")

for (Ticker in tickers_index){
  ticker_data <- cbind(ticker_data,
                       getSymbols.yahoo(Ticker, from="2021-12-01", to="2023-12-01", 
                                        periodicity = "weekly",auto.assign=FALSE)[,6])
}

# Check length and min max date
length(ticker_data$XLI.Adjusted)
summary(ticker_data)[c(1, 6)]
head(ticker_data)
```

```{r, eval=FALSE, include=FALSE}
# Google Trends data
gtrends_war_web <- gtrends(
  keyword = "war",
  time = "2021-11-30 2023-12-01",
  gprop = "web"
)$interest_over_time
head(gtrends_war_web)
```

```{r, include=FALSE}
# If gtrends does not work --> response 429
library(lubridate)

gtrends_war_web <- read.csv('gtrends_war_web.csv')
gtrends_war_web <- gtrends_war_web %>%
  mutate(date = ymd(date))
head(gtrends_war_web)
```


```{r, include=FALSE}
# Increase date by one day to match ticker data --> starts on Sunday, Ticker start on Monday
gtrends_war_web$date <- gtrends_war_web$date + days(1)

# Check length and min max date
length(gtrends_war_web$date)
min(gtrends_war_web$date)
max(gtrends_war_web$date)
```

```{r, include=FALSE}
# Remove first date of ticker data to match gtrends data
ticker_data <- ticker_data[-1,]
head(ticker_data)
```

```{r, include=FALSE}
### Import Inflation Data
inflation_data <- read.csv('inflation_rates.csv')
head(inflation_data)
min(inflation_data$TIME)
max(inflation_data$TIME)
```

```{r, include=FALSE}
# Select dates from December 2021 until December 2023
inflation_data <- inflation_data %>%
  filter(TIME >= '2021-12' & TIME <= '2023-12')

# Take only USA
inflation_data <- inflation_data %>%
  filter(LOCATION == 'USA') %>%
  mutate(AVG_INFLATION = Value) %>%
  dplyr::select(TIME, AVG_INFLATION)

# Drop duplicates from ungrouping
inflation_data <- inflation_data %>%
  distinct(TIME, AVG_INFLATION, .keep_all = TRUE)

# Max date is 2023-10 assume that this stays same for 2023-11 and 2023-12
max(inflation_data$TIME)
inflation_october_23 <- subset(inflation_data, TIME == "2023-10")$AVG_INFLATION
inflation_november_23 <- data.frame(TIME='2023-11', AVG_INFLATION=inflation_october_23)
inflation_december_23 <- data.frame(TIME='2023-12', AVG_INFLATION=inflation_october_23)

# Create final df
inflation_data <- bind_rows(inflation_data, inflation_november_23)
inflation_df <- bind_rows(inflation_data, inflation_december_23)
```

### **Financial Data**

The financial data used for this analysis comes from Yahoo Finance [@YahooFin97]. The data can be retrieved using the `getSynmbols.yahoo()` function from the `quantmod` package. The data represents the weekly adjusted closing prices for the tickers introduced in chapter 1 for the time frame from December 2021 until December 2023. The mentioned time frame was chosen as it captures the start of the Russian invasion of Ukraine as well as the start of the Israel-Hamas war. Additionally, the time frame and periodicity should have a good balance between having enough data points and keeping the data set manageable and focused. Adjusted closing prices were chosen over closing prices because they are adapted to address any splits, dividends or capital gain distributions [@Groww]. Lastly, the weekly periodicity of the ticker data was chosen, as the Google Trends data comes in weekly measurements.

When we look at the plot of the two indices, we see that they are not stationary. In the materials sector, the variance doesn't seem to be constant, and there might be some seasonality and some trend involved. The same holds true for the industrial sector. 

```{r, include=FALSE}
### Visualize Ticker Data
# Visualization
ticker_data_df <- fortify.zoo(ticker_data)
colnames(ticker_data_df)[1] <- "Date"
ticker_data_df <- gather(ticker_data_df, key="Ticker", value="Value", 
                         c("XLI.Adjusted", "XLB.Adjusted"), -Date)

head(ticker_data_df)
```

```{r, fig.height=4, echo=FALSE}
# Line Chart
# New facet label names for ticker_data
ticker.labs <- c("XLI: Industrial", "XLB: Materials")
names(ticker.labs) <- c("XLI.Adjusted", "XLB.Adjusted")

# Create the plot
ggplot(ticker_data_df, aes(Date, Value)) +
  geom_line(color='darkseagreen3') +
  facet_wrap(~Ticker, labeller = labeller(Ticker = ticker.labs)) +
  ggtitle("Ticker Time Series") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5)) +
  ylab('Adjusted Close')
```


```{r, include=FALSE}
# Check stationarity of ticker Data
sapply(ticker_data, adf.test)
```

To further verify this assumption, an "*Augmented Dickey-Fuller Test*" is conducted for both time series. For the materials sector, the p-Value is `r round(adf.test(ticker_data$XLB.Adjusted)$p.value, 2)`, which means the time series is non-stationary. For the industrial sector, the p-Value of `r round(adf.test(ticker_data$XLI.Adjusted)$p.value, 2)` is below 0.05, which means the time series is stationary. Because it is only slightly below 0.05, we differentiate it as well. This is since financial time series generally tend to consist of a drift component, which leads to non-stationarity [@AnkenbrandBieri]. Also, both time series are logarithmized. Afterwards both time series have p-Values below 0.01 in the "*Augmented Dickey-Fuller Test*" and are therefore stationary. A visual inspection leads to the same conclusion (see Appendix).

```{r, include=FALSE}
ticker_data_differenced <- NULL
ticker_data_differenced$XLB.Adjusted <- na.omit(diff(log(ticker_data$XLB.Adjusted)))
ticker_data_differenced$XLI.Adjusted <- na.omit(diff(log(ticker_data$XLI.Adjusted)))
```


```{r, include=FALSE}
# Check stationarity again after diff-log transformation
sapply(ticker_data_differenced, adf.test)

# Make tickers in list to dataframe
ticker_data_differenced_df <- do.call(cbind.data.frame, ticker_data_differenced)

# Make date index to column for merging
ticker_data_differenced_df$date <- rownames(ticker_data_differenced_df)
```


### **Google Trends Data**

To import the Google Trends data, the package `gtrendsR` is used. The package allows querying the data of interest over time for a keyword. In the case of this study, the keyword *war* in web searches was chosen as it is considered to capture all conflicts alike. When it comes to the geographical origin of the searches, the whole world was considered, as the study aims to give a generalized and non-location-specific view of the crisis level regarding war. The returned data from Google Trends is normalized over the queried time frame and reflects the search volume for a keyword on a scale from 0-100, where 100 means very high interest and 0 means no interest [@GoogleTrend]. 

The data reveals three spikes: one can be attributed to the start of the Russian invasion in Ukraine, one to the attack of Hamas in Israel, and the third is a bit unclear but could be traced back to events in the Russian invasion of Ukraine [@WEF]. This also goes to show that the data might not be stationary. The "*Augmented Dicky Fuller Test*" gives a p-Value of `r round(adf.test(gtrends_war_web$hits)$p.value,2)` which is slightly below 0.05. Because the p-value is only slightly below 0.05, the first difference is taken. Additionally, the series is logarithmized. After this transformation, the p-value of the "*Augmented Dicky Fuller Test*" is below 0.01. Also, on visual inspection, the data now looks stationary (see Appendix).

```{r fig.align="center", fig.width=12, fig.height=5, echo=FALSE}
### Visualize Google Trends Data
# Line chart

# Convert 'date' column to POSIXct format
gtrends_war_web$date <- as.POSIXct(gtrends_war_web$date, format = "%Y-%m-%d")

ggplot(gtrends_war_web, aes(date, hits)) +
  geom_line(color='darkseagreen3') +
  theme_minimal() +
  ggtitle("Google Trends - Evolving Interest in Search Word 'War'") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5)) +
  geom_vline(xintercept = as.POSIXct("2022-02-24"), linetype="dashed", 
             color = "black", size=0.5) +
  annotate('label', x=as.POSIXct("2022-02-24"), y=80, 
           label="Start Russian Invasion of Ukraine", vjust=2, color="black") +
  geom_vline(xintercept = as.POSIXct("2023-10-07"), linetype="dashed", 
               color = "black", size=0.5) +
  annotate('label', x=as.POSIXct("2023-10-07"), y=80, 
             label="Start Israel-Hamas War", vjust=2, color="black") +
  ylab("Search Volume") +
  xlab("Date")

```

```{r, include=FALSE}
#### Augmented Dicky Fuller Test on Google Trends Data
adf.test(gtrends_war_web$hits)
```


```{r, include=FALSE}
# Make Google Trends data stationary
logged_diff_hits <- na.omit(diff(log(gtrends_war_web$hits)))

corresponding_dates <- gtrends_war_web[-1,]$date # +1 due to diff reduction

gtrends_war_web_differenced <- data.frame(
  date = corresponding_dates,
  hits = logged_diff_hits
)
# Check stationarity after diff-log-transformation
adf.test(gtrends_war_web_differenced$hits)
```


```{r, include=FALSE}
# Check length of time series (google trends and ticker-data)
length(gtrends_war_web_differenced$date) == length(ticker_data_differenced$XLI.Adjusted)
length(gtrends_war_web_differenced$date)
length(ticker_data_differenced$XLI.Adjusted)
min(gtrends_war_web_differenced$date)
max(gtrends_war_web_differenced$date)
```

### **Inflation Data**

In order to handle potential confounding variables that could cause spurious correlations due to their influence on the dependent and independent variables, it is important to also include a control variable that represents the general economic state. Therefore, the inflation rate is included as well, which was retrieved from the OECD [@oecd2023inflation]. As the indices come from American companies, only the inflation rate from the USA was included.

The inflation data shows a very clear trend. First, it goes up until mid-2022, and then it constantly comes back down. So this time series is clearly non-stationary. The "*Augmented Dicky Fuller Test*" has a p-Value of `r round(adf.test(inflation_df$AVG_INFLATION)$p.value, 2)`. To make the data stationary, it had to be differenced twice and also logarithmized. A visualization of the stationary inflation data is in the appendix.

```{r fig.align="center", fig.width=12, fig.height=5, echo=FALSE}
### Visualize Inflation Data
# Line chart

ggplot(inflation_df, aes(TIME, AVG_INFLATION)) +
  geom_line(color='darkseagreen3', group = 1) +
  theme_minimal() +
  ggtitle("Inflation in the USA") +
  ylab("Inflation in %") +
  xlab("Date") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))

```

```{r, include=FALSE}
# Check stationarity of inflation data
adf.test(inflation_df$AVG_INFLATION)
```

```{r, include=FALSE}
diff_inflation <- na.omit(diff(diff(log(inflation_df$AVG_INFLATION))))

corresponding_dates <- inflation_df[c(-1, -2),]$TIME # +1 due to diff reduction

inflation_differenced <- data.frame(
  TIME = corresponding_dates,
  AVG_INFLATION = diff_inflation
)
# Check stationarity after diff-log-transformation
adf.test(inflation_differenced$AVG_INFLATION)
```


```{r, include=FALSE}
### Create final dataframe

# Make date in gtrends to character in order to merge
gtrends_war_web_differenced$date <- format(gtrends_war_web_differenced$date, format = "%Y-%m-%d")

# Merge
war_ticker_df <- left_join(gtrends_war_web_differenced, ticker_data_differenced_df)
```


```{r, include=FALSE}
# Add inflation data
# Create year month column for joining inflation data
war_ticker_df <- war_ticker_df %>%
  mutate(year_month = format(as.Date(date), "%Y-%m"))

# Join dataframe
war_ticker_inflation_df <- left_join(war_ticker_df, inflation_differenced, by=c('year_month'='TIME'))

# Delete NA's that were introduced because of differencing of inflation
war_ticker_inflation_df <- na.omit(war_ticker_inflation_df)
```


## 4. Results and Discussion

After the stationary data from the different time series is combined into one data frame, the VAR can be conducted. One model is run for each of the two indices. As information criteria to choose the best lag, the AIC (Akaike information criterion) is used. We are not only interested in the short-term effects of the crisis measure but in its effect on the whole time frame. Therefore, we chose the largest possible `lag.max`, which was 21 and comes from the volume of the data. 

```{r, include=FALSE}
# Create ticker list
ticker_cols <- colnames(war_ticker_inflation_df)[3:4]

# Create matrix to store p.Values of Granger-Test
var_ticker <- matrix(NA, ncol = 3, nrow = 2)
colnames(var_ticker) <- c('p.Value.war','p.Value.index', 'p.Value.inflation')
rownames(var_ticker) <- colnames(war_ticker_df)[3:4]

# Create matrix to store selected lags
lag_selected_matrix <- matrix(NA, ncol = 4, nrow = length(ticker_cols))
colnames(lag_selected_matrix) <- c('AIC', 'HQ', 'SC', 'FPE')
rownames(lag_selected_matrix) <- ticker_cols

# List to store plots
irf_plots_list <- list()

for (Ticker in ticker_cols) {
  
  # Create data for VAR
  print(Ticker)
  data_for_var <- cbind(war_interest=war_ticker_inflation_df$hits,
                        ticker=war_ticker_inflation_df[[Ticker]],
                        inflation=war_ticker_inflation_df$AVG_INFLATION)
  
  # Run VAR model
  VAR_est <- VAR(data_for_var, ic = "AIC", lag.max = 21)
  coefs <-coeftest(VAR_est)
  summ <- summary(VAR_est)
  lag_selected <- VARselect(data_for_var, lag.max = 21, type = "both")
  
  #print(coefs)
  print(summ)
  print(Ticker)
  print(lag_selected)
  
  # Run Granger Causality Test
  causal <- causality(VAR_est, cause="war_interest")["Granger"]
  #print(causal)
  var_ticker[Ticker,1] <- causal$Granger$p.value
  
  # Run Granger Causality Test other way (check if index has influence on crisis measure)
  causal_ticker <- causality(VAR_est, cause="ticker")["Granger"]
  #print(causal_ticker)
  var_ticker[Ticker,2] <- causal_ticker$Granger$p.value
  
  # Run Granger Causality Test for inflation
  causal_ticker <- causality(VAR_est, cause="inflation")["Granger"]
  #print(causal_ticker)
  var_ticker[Ticker,3] <- causal_ticker$Granger$p.value
  
  # Store selected lag for information criterion
  lag_selected_matrix[Ticker, 'AIC'] <- lag_selected$selection["AIC(n)"]
  lag_selected_matrix[Ticker, 'HQ'] <- lag_selected$selection["HQ(n)"]
  lag_selected_matrix[Ticker, 'SC'] <- lag_selected$selection["SC(n)"]
  lag_selected_matrix[Ticker, 'FPE'] <- lag_selected$selection["FPE(n)"]
  
  # Save Impulse response functions
  plot(irf(VAR_est, impulse="war_interest", response="ticker"), main=Ticker)
  irf_plots_list[[Ticker]] <- recordPlot()
  
}

```

To determine if the crisis measure has an influence on the indices, a "*Granger Causality Test*" was carried out. The test was also executed for the indices and the inflation as cause. In the output below, the p-values from the "*Granger Causality Test*" are displayed for the different causes. For both sectors, the influence of the Google Trends data for the search term *"war"* is higher than 0.05 and therefore not significant. In conclusion, the materials and industrial sectors do not profit from war.

```{r, echo=FALSE}
# Print results of Granger Test
knitr::kable(var_ticker[order(var_ticker[,1], decreasing=FALSE),])
```


Taking a closer look at the chosen lag of the VAR model for different information criteria shows that for the ticker XLI (Industrial Select Sector), AIC and HQ minimized at the maximum lag 21, whereas the other information criteria minimized at the first lag. For XLB (Materials Select Sector), the AIC also minimized at the maximum lag, whereas the other information criterion minimized at the first lag. 

```{r, echo=FALSE}
# Print selected lags of VAR
knitr::kable(lag_selected_matrix)
```

This can result as AIC aims to balance model complexity against goodness of fit. However, for rather small data sets, such as the data set used in this paper, the AIC can have the tendency to favor more complex models [@aicbic], especially when there is a high change in the data for later time points, as in the inflation data (see inflation plot). Therefore, more complex models could be seen as more suitable for the AIC in such cases, as they capture the mentioned changes  more accurately. Taking a closer look at the "*Impulse Response Charts*" (see Appendix) shows that a shock at lag 0 still leads to an increase at a much later lags, whereas for XLB the highest increase even comes at the end of the plot, which supports this assumption as later changes are significant and should be captured in the model. Therefore, it could be that the control variable, inflation, influences the model too much. 

Running the VAR model again, without including inflation as a control variable (see Appendix) shows that we still do not end up with significant causality. However, inspecting the selected lags for the different information criteria and the "*Impulse Response Charts*", shows that the simplest model was chosen for all criteria and that there is no more a high influence on later lags by shocking at lag 0. This lets us prove that the inflation data has had a big influence on the model.


```{r, include=FALSE}
# Run models again, but this time without Inflation as control variable

# Create matrix to store p.Values of Granger-Test
var_ticker_without_inflation <- matrix(NA, ncol = 2, nrow = 2)
colnames(var_ticker_without_inflation) <- c('p.Value.war','p.Value.index')
rownames(var_ticker_without_inflation) <- colnames(war_ticker_df)[3:4]

# Create matrix to store selected lags
lag_selected_matrix_without_inflation <- matrix(NA, ncol = 4, nrow = length(ticker_cols))
colnames(lag_selected_matrix_without_inflation) <- c('AIC', 'HQ', 'SC', 'FPE')
rownames(lag_selected_matrix_without_inflation) <- ticker_cols

# List to store plots
irf_plots_list_without_inflation <- list()

for (Ticker in ticker_cols) {
  
  # Create data for VAR
  print(Ticker)
  data_for_var <- cbind(war_interest=war_ticker_inflation_df$hits,
                        ticker=war_ticker_inflation_df[[Ticker]])
  
  # Run VAR model
  VAR_est <- VAR(data_for_var, ic = "AIC", lag.max = 21)
  coefs <-coeftest(VAR_est)
  summ <- summary(VAR_est)
  lag_selected <- VARselect(data_for_var, lag.max = 21, type = "both")
  
  #print(coefs)
  print(summ)
  print(Ticker)
  print(lag_selected)
  
  # Run Granger Causality Test
  causal <- causality(VAR_est, cause="war_interest")["Granger"]
  #print(causal)
  var_ticker_without_inflation[Ticker,1] <- causal$Granger$p.value
  
  # Run Granger Causality Test other way (check if index has influence on crisis measure)
  causal_ticker <- causality(VAR_est, cause="ticker")["Granger"]
  #print(causal_ticker)
  var_ticker_without_inflation[Ticker,2] <- causal_ticker$Granger$p.value
  
  # Store selected lag for information criterion
  lag_selected_matrix_without_inflation[Ticker, 'AIC'] <- lag_selected$selection["AIC(n)"]
  lag_selected_matrix_without_inflation[Ticker, 'HQ'] <- lag_selected$selection["HQ(n)"]
  lag_selected_matrix_without_inflation[Ticker, 'SC'] <- lag_selected$selection["SC(n)"]
  lag_selected_matrix_without_inflation[Ticker, 'FPE'] <- lag_selected$selection["FPE(n)"]
  
  # Save Impulse response functions
  plot(irf(VAR_est, impulse="war_interest", response="ticker"), main=Ticker)
  irf_plots_list_without_inflation[[Ticker]] <- recordPlot()
  
}
```



## 5. Conclusion

This paper looked into the effect of war on the performance of two sector-specific indices. Specifically, the hypothesis was that the materials and industrial sectors are profiteers of war. To verify this hypothesis a VAR including inflation as a control variable was performed. The "*Granger Causality Test*" did not show a significant effect of war on the two sectors for a VAR including inflation as a control variable or without. Therefore, the hypotheses could not be confirmed. Additionally, it was observed that inflation had a notable influence on the model selection, leading to selected models with higher lags.

Future research could look into other measures for war, as the Google Trends data might not capture this correctly. Also, the results were influenced by the control variable (inflation) due to higher changes at later time points. Therefore, it might be interesting to look into other control variables that capture the general economic state. Also, it could be interesting to look into the effect of war on other indices, or maybe only single companies and not whole sectors. And lastly, it could be interesting to repeat the analysis over a longer time period. 

\newpage
## Appendix

**Histogram of Financial Data**

```{r, fig.height=3, echo=FALSE, message=FALSE}
# Histogram
ggplot(ticker_data_df, aes(Value)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  facet_wrap(~Ticker, labeller = labeller(Ticker = ticker.labs)) +
  ggtitle("Ticker Distributions") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))

```

**Diff-Log-Transformed Financial Data**

```{r, fig.height=3, echo=FALSE}
par(mfrow = c(1, 2))
plot(ts(ticker_data_differenced_df$XLB.Adjusted))
plot(ts(ticker_data_differenced_df$XLI.Adjusted))
```

\newpage
**Histogram of Google Trends Data**

```{r, fig.height=3, echo=FALSE, message=FALSE}
# Histogram
ggplot(gtrends_war_web, aes(hits)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  ggtitle("Search Word 'War' Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```

**Diff-Log-Transformed Google Trends Data**

```{r, fig.height=3, echo=FALSE}
par(mfrow = c(1, 1))
plot(ts(gtrends_war_web_differenced$hits))
```

\newpage
**Histogram Inflation**

```{r, fig.height=3, echo=FALSE, message=FALSE}
# Histogram
ggplot(inflation_df, aes(AVG_INFLATION)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  ggtitle("Inflation Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```

**Diff-Log-Transformed Inflation Data**

```{r, fig.height=3, echo=FALSE}
par(mfrow = c(1, 1))
plot(ts(inflation_differenced$AVG_INFLATION))
```

\newpage
**Impulse Response Function for VAR of Ticker, War Interest and Inflation**
```{r, fig.height=4, echo=FALSE}
irf_plots_list$XLB.Adjusted
irf_plots_list$XLI.Adjusted
```

\newpage
**Granger Causality Test for VAR without Inflation**
```{r, echo=FALSE}
# Print results of Granger Test
knitr::kable(var_ticker_without_inflation[order(var_ticker_without_inflation[,1], decreasing=FALSE),])
```

**Selected Lags of Information Criterion for VAR without Inflation**
```{r, echo=FALSE}
# Print selected lags of VAR
knitr::kable(lag_selected_matrix_without_inflation)
```


\newpage
**Impulse Response Function for VAR of Ticker and War Interest without Inflation**
**Impulse Response Function for VAR of Ticker, War Interest and Inflation**
```{r, fig.height=4, echo=FALSE}
irf_plots_list_without_inflation$XLB.Adjusted
irf_plots_list_without_inflation$XLI.Adjusted
```


\newpage
## Bibliography

