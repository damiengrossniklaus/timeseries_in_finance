---
output:
  pdf_document:
    toc: no
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```
\begin{center}
\vspace*{75pt}
\Huge \textbf{Who are the financial profiteers of war?} \\
\vspace{50pt}
\Large University of Applied Sciences Lucerne \\[10pt]
\Large Master of Science in Applied Information and Data Science \\[10pt]
\Large Time Series in Finance (TSA01) \\[10pt]
\vspace{50pt}
\Large Authors: Michèle Gerber and Damien Grossniklaus \\
\Large Date of Submission: 22. December 2023 \\
\end{center}



\newpage
```{=latex}
\setcounter{tocdepth}{4}
\tableofcontents
```
\newpage


```{r, eval=FALSE, echo=FALSE, results=FALSE}
install.packages("readr")
install.packages("colorspace")
install.packages("vctrs")
install.packages("gtrendsR")
```


```{r, echo=FALSE, results=FALSE, message=FALSE, include=FALSE}
library(quantmod)
library(tseries)
#library(readr) #Disable in order to Google trends package to work
library(gtrendsR)
library(lubridate)
library(ggplot2)
library(zoo)
library(dplyr)
library(tidyr)
library(vars)
```


```{r, eval=FALSE, include=FALSE}
TODO:
* Ticker Section Mentioning in Charts and Code 
    --> in Einleitung erwähnt und in Grafik angepasst
* Nach differencing nochmals Stationarity testen
    --> ergänzt
* Casality testing andere Seite --> Einfluss Ticker auf Trends ausschliessen
    --> in Code ergänzt
* Add Inflation as Controll Variable
    --> angefangen und ergänzt. Bitte kontrollieren.
    --> Habe noch den den Weekly Economic Index gefunden (siehe weitere Infos in Abschnitt 'Closer Look'). Dieser Index könnte abdecken, was Denis in der Rückmeldung angebracht hat ("relevant control variables (such as the general economic development)"). Aber Inflation würde wohl auch ausreichen.


**Potential structure**

- Context and Goal (Literature?)
- Methods
- Data
  - Import data (indices & Google words)
  - Describe data
  - Preprocessing
- VAR & Causality Testing
- Results & Discussion
```

## 1. Introduction

With recent outbreaks of war (e.g., in Israel or in the Ukraine), the question arises of how stock markets react to this and if there are sectors that profit from such crises. Specifically, this case study examines if several indices from specific economic sectors perform well in situations of crisis. The following two indices are included in the analysis:

* **XLI**: Industrial Select Sector
* **XLB**: Materials Select Sector

Essentially our research question is the following: *Who are the financial profiteers of war?*. To answer this question, the performance of the sector-specific indices should be compared to an overall crisis measure. As an overall crisis measure the Google Trend data for the search word *"war"* is used. We postulate, that an increased search for this term points to a higher crisis. So in conclusion, we want to examine if there are positive correlations between our crisis measure and stock market profits in the different indices. 

## 2. Methods and Hypotheses

Our research question is of an exploratory nature. Therefore we don't have a hypothesis going in, as to which indices will perform better under situations of crisis. 
The method we will us is vector autoregression (VAR). This allows us to measure the influence of our crisis measure on the performance of the different indices. For each index we will calculate a separate model. Furthermore, to address potential spurious correlations a Granger causality test will be conducted for every ticker. However, before a VAR and causality test can be carried out the data in form of different time series has to be imported, cleaned and pre-processed. Concretely, potential seasonal effects and trends in time series have to be identified and adjusted for to achieve stationarity, which characterizes a stabilized mean and variance for the time series over time and will ultimately allow more reliable and accurate modeling. To test the stationarity of a time the "*Augmented Dickey-Fuller Test*" will be carried out. If a time series is non-stationary, lagged differences will be calculated. Lastly, to deal with right skewness and achieve normal distributions in the data, the time series will first be logarithmized before applying the difference.

## 3. Data Sources

**Financial Data**

The financial data used for the paper at hand comes from Yahoo Finance (2023)(**SOURCE**). The data can be retrieved using the `getSynmbols.yahoo()` function from the `quantmod` package. The data represents the weekly adjusted closing prices for the tickers introduced in chapter 1 for the time frame from December 2021 until December 2023. Mentioned time frame was chosen as it captures the start of the Russian invasion of Ukraine as well as the start of the Israel-Hammas war. Additionally, the time frame and periodicity is considered of good balance between having enough data points as well as keeping the data set manageable and focused. The decision to use the adjusted closing prices instead of the closing price can be justified that adjusted prices are adapted to address any splits, dividends or capital gain distributions. Lastly, the weekly periodicity of the ticker data was chosen as the Google Trends data comes in weekly measurements.

**Google Trends Data**

To import the Google Trends data the package `gtrendsR` is used. The package allows to query the data of the interest over time for a keyword. In the case of this study the keyword *war* in web searches was chosen, as it is considered to capture all conflicts alike. When it comes to the geographical origin of the searches the whole world was considered as the study aims to give a generalized and non location specific view. Returned data from Google Trends is normalized and reflects the search volume for a keyword on a scale from 0-100, where 100 means very high interest and 0 no interest. (**SOURCE: https://newsinitiative.withgoogle.com/en-gb/resources/trainings/fundamentals/google-trends-understanding-the-data/#:~:text=The%20percentages%20are%20based%20on,for%20the%2030%20days%20prior.**)

https://cran.r-project.org/web/packages/gtrendsR/gtrendsR.pdf

**Inflation Data**

In order to handle potential confounding variables that could cause spurious associations due to influence on the dependent and independent variable, it is important to also include a control variable that represents the general economic state. Therefore, the worldwide inflation rate is included as well, which was retrieved from the OECD. To allow a simple aggregation the mean inflation rate per month for every available country in the data set was calculated.

https://data.oecd.org/price/inflation-cpi.htm


### Import Time Series Data


TODO: 
- Justify why Adjusted values and not close values
- Timeframe: December 2021 until December 2023

```{r, include=FALSE}
# Ticker Data
ticker_data <- NULL
tickers_index <- c("XLI", "XLB")

for (Ticker in tickers_index){
  ticker_data <- cbind(ticker_data,
                       getSymbols.yahoo(Ticker, from="2021-12-01", to="2023-12-01", 
                                        periodicity = "weekly",auto.assign=FALSE)[,6])
}

# Check length and min max date
length(ticker_data$XLI.Adjusted)
summary(ticker_data)[c(1, 6)]
head(ticker_data)
```


```{r, eval=FALSE, include=FALSE}
# Google Trends data
gtrends_war_web <- gtrends(
  keyword = "war",
  time = "2021-11-30 2023-12-01",
  gprop = "web"
)$interest_over_time
head(gtrends_war_web)
```

```{r, eval=FALSE, include=FALSE}
# Too many requests exclude?
gtrends_war_news <- gtrends(
  keyword = "war",
  time = "2021-12-01 2023-12-01",
  gprop = "news"
)$interest_over_time
```

```{r, include=FALSE}
# If gtrends does not work --> response 429
library(lubridate)

gtrends_war_web <- read.csv('gtrends_war_web.csv')
gtrends_war_web <- gtrends_war_web %>%
  mutate(date = ymd(date))
head(gtrends_war_web)

```

Google Trends delivers data always starting from Sunday. This has to be transformed in order to fit with the weekly data from the financial tickers, which always start at Monday.

```{r, include=FALSE}
# Increase date by one day to match ticker data
gtrends_war_web$date <- gtrends_war_web$date + days(1)

# Check length and min max date
length(gtrends_war_web$date)
min(gtrends_war_web$date)
max(gtrends_war_web$date)
```

```{r, include=FALSE}
# Remove first date of ticker data to match gtrends data
ticker_data <- ticker_data[-1,]
head(ticker_data)
```


### Inflation Data
```{r, include=FALSE}
inflation_data <- read.csv('inflation_rates.csv')
head(inflation_data)
min(inflation_data$TIME)
max(inflation_data$TIME)
```

Aggregation and preprocessing
```{r, include=FALSE}
# Select dates from December 2021 until December 2023
inflation_data <- inflation_data %>%
  filter(TIME >= '2021-12' & TIME <= '2023-12')

# Take mean per month
inflation_data <- inflation_data %>%
  group_by(TIME) %>%
  mutate(AVG_INFLATION = mean(Value)) %>%
  ungroup() %>%
  dplyr::select(TIME, AVG_INFLATION)

# Drop duplicates from ungrouping
inflation_data <- inflation_data %>%
  distinct(TIME, AVG_INFLATION, .keep_all = TRUE)

# Max date is 2023-11 assume that this stays same for 2023-12
max(inflation_data$TIME)
inflation_november_23 <- subset(inflation_data, TIME == "2023-11")$AVG_INFLATION
inflation_december_23 <- data.frame(TIME='2023-12', AVG_INFLATION=inflation_november_23)

# Create final df
inflation_df <- bind_rows(inflation_data, inflation_december_23)
```


### Visualize Ticker Data

```{r, include=FALSE}
# Visualization
ticker_data_df <- fortify.zoo(ticker_data)
colnames(ticker_data_df)[1] <- "Date"
ticker_data_df <- gather(ticker_data_df, key="Ticker", value="Value", 
                         c("XLI.Adjusted", "XLB.Adjusted"), -Date)

head(ticker_data_df)
```

```{r, echo=FALSE}
# Line Chart
# New facet label names for ticker_data
ticker.labs <- c("XLI: Industrial", "XLB: Materials")
names(ticker.labs) <- c("XLI.Adjusted", "XLB.Adjusted")

# Create the plot
ggplot(ticker_data_df, aes(Date, Value)) +
  geom_line(color='darkseagreen3') +
  facet_wrap(~Ticker, labeller = labeller(Ticker = ticker.labs)) +
  ggtitle("Ticker Time Series") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```

```{r, echo=FALSE, message=FALSE}
# Histogram
ggplot(ticker_data_df, aes(Value)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  facet_wrap(~Ticker, labeller = labeller(Ticker = ticker.labs)) +
  ggtitle("Ticker Distributions") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))

```


### Visualize Google Trends Data
```{r fig.align="center", fig.width=12, fig.height=4, echo=FALSE}
# Line chart

# Convert 'date' column to POSIXct format
gtrends_war_web$date <- as.POSIXct(gtrends_war_web$date, format = "%Y-%m-%d")

ggplot(gtrends_war_web, aes(date, hits)) +
  geom_line(color='darkseagreen3') +
  theme_minimal() +
  ggtitle("Google Trends - Evolving Interest in Search Word 'War'") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5)) +
  geom_vline(xintercept = as.POSIXct("2022-02-24"), linetype="dashed", 
             color = "black", size=0.5) +
  annotate('label', x=as.POSIXct("2022-02-24"), y=80, 
           label="Start Russian Invasion of Ukraine", vjust=2, color="black") +
  geom_vline(xintercept = as.POSIXct("2023-10-07"), linetype="dashed", 
               color = "black", size=0.5) +
  annotate('label', x=as.POSIXct("2023-10-07"), y=80, 
             label="Start Israel-Hammas War", vjust=2, color="black")
  

```


```{r, echo=FALSE, message=FALSE}
# Histogram
ggplot(gtrends_war_web, aes(hits)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  ggtitle("Search Word 'War' Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```

### Visualize Inflation Data
```{r fig.align="center", fig.width=12, fig.height=4, echo=FALSE}
# Line chart

ggplot(inflation_df, aes(TIME, AVG_INFLATION)) +
  geom_line(color='darkseagreen3', group = 1) +
  theme_minimal() +
  ggtitle("Inflation - Global average") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))

```


```{r, echo=FALSE, message=FALSE}
# Histogram
ggplot(inflation_df, aes(AVG_INFLATION)) +
  geom_histogram(color='darkseagreen3', fill='darkseagreen3') +
  ggtitle("Inflation Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```


### Stationarity test and adjustment

#### Ticker Data

```{r, include=FALSE}
# Check stationarity
sapply(ticker_data, adf.test)
```

XLB is non-stationary. Make it stationary. XLI is stationary, therefore only log it.

```{r, include=FALSE}
ticker_data_differenced <- NULL
ticker_data_differenced$XLB.Adjusted <- na.omit(diff(log(ticker_data$XLB.Adjusted)))

# Already stationary ticker series 
ticker_data_differenced$XLI.Adjusted <- log(ticker_data$XLI.Adjusted)

# For non differenced time series remove first row
ticker_data_differenced$XLI.Adjusted <-  ticker_data_differenced$XLI.Adjusted[-1,]
```

```{r, include=FALSE}
# Check stationarity again after diff-log transformation
sapply(ticker_data_differenced, adf.test)
```

After the diff-log-transformation all the time series are stationary.

#### Google Trends Data
```{r, include=FALSE}
adf.test(gtrends_war_web$hits)
```

Not stationary and distribution has long tail on right --> Log Diff. Although p value is slightly below 0.05.
```{r, include=FALSE}
logged_diff_hits <- na.omit(diff(log(gtrends_war_web$hits)))

corresponding_dates <- gtrends_war_web[-1,]$date # +1 due to diff reduction

gtrends_war_web_differenced <- data.frame(
  date = corresponding_dates,
  hits = logged_diff_hits
)
# Check stationarity after diff-log-transformation
adf.test(gtrends_war_web_differenced$hits)
```

Check that differenced time series have same length.

```{r, include=FALSE}
# Check length of time series
length(gtrends_war_web_differenced$date) == length(ticker_data_differenced$XLK.Adjusted)
length(gtrends_war_web_differenced$date)
length(ticker_data_differenced$XLK.Adjusted)
min(gtrends_war_web_differenced$date)
max(gtrends_war_web_differenced$date)
```

#### Inflation Data
```{r, include=FALSE}
adf.test(inflation_df$AVG_INFLATION)
```

Inflation time series is not stationary.

```{r, include=FALSE}
diff_inflation <- na.omit(diff(log(inflation_df$AVG_INFLATION)))

corresponding_dates <- inflation_df[-1,]$TIME # +1 due to diff reduction

inflation_differenced <- data.frame(
  TIME = corresponding_dates,
  AVG_INFLATION = diff_inflation
)
# Check stationarity after diff-log-transformation
adf.test(inflation_differenced$AVG_INFLATION)
```



### Create final dataframe
```{r, include=FALSE}
# Make tickers in list to dataframe
ticker_data_differenced_df <- do.call(cbind.data.frame, ticker_data_differenced)

# Make date index to column for merging
ticker_data_differenced_df$date <- rownames(ticker_data_differenced_df)

# Make date in gtrends to character in order to merge
gtrends_war_web_differenced$date <- format(gtrends_war_web_differenced$date, format = "%Y-%m-%d")

# Merge
war_ticker_df <- left_join(gtrends_war_web_differenced, ticker_data_differenced_df)
```

Add inflation data
```{r, include=FALSE}
# Create year month column for joining inflation data
war_ticker_df <- war_ticker_df %>%
  mutate(year_month = format(as.Date(date), "%Y-%m"))

# Join dataframe
war_ticker_inflation_df <- left_join(war_ticker_df, inflation_differenced, by=c('year_month'='TIME'))

# Delete NA's that were introduced because of differencing of inflation
war_ticker_inflation_df <- na.omit(war_ticker_inflation_df)
```


## 4. Results and Discussion

### VAR & Causality Testing

TODO:
- Check lag.max what to apply
- Control variable?
- Allenfalls den Ouptput im for-Loop weglassen und in neuem Kapitel "Closer Look" für den signifikanten Index ergänzen

```{r, include=FALSE}
# Create ticker list
ticker_cols <- colnames(war_ticker_inflation_df)[3:4]

# Create matrix to store p.Values of Granger-Test
var_ticker <- matrix(NA, ncol = 3, nrow = 2)
colnames(var_ticker) <- c('p.Value','p.Value.reversed', 'p.Value.inflation')
rownames(var_ticker) <- colnames(war_ticker_df)[3:4]

for (Ticker in ticker_cols) {
  
  # Create data for VAR
  print(Ticker)
  data_for_var <- cbind(war_interest=war_ticker_inflation_df$hits,
                        ticker=war_ticker_inflation_df[[Ticker]],
                        inflation=war_ticker_inflation_df$AVG_INFLATION)
  
  # Run VAR model
  VAR_est <- VAR(data_for_var, ic = "AIC", lag.max = 24)
  coefs <-coeftest(VAR_est)
  summ <- summary(VAR_est)
  
  print(coefs)
  #print(summ)
  
  # Run Granger Causality Test
  causal <- causality(VAR_est, cause="war_interest")["Granger"]
  print(causal)
  var_ticker[Ticker,1] <- causal$Granger$p.value
  
  # Run Granger Causality Test other way (check if index has influence on crisis measure)
  causal_ticker <- causality(VAR_est, cause="ticker")["Granger"]
  print(causal_ticker)
  var_ticker[Ticker,2] <- causal_ticker$Granger$p.value
  
  # Run Granger Causality Test for inflation
  causal_ticker <- causality(VAR_est, cause="inflation")["Granger"]
  print(causal_ticker)
  var_ticker[Ticker,3] <- causal_ticker$Granger$p.value
  
  # Impulse response functions
  plot(irf(VAR_est, impulse="war_interest", response="ticker"))
  
}

```


```{r, echo=FALSE}
# Print results of Granger Test
print(var_ticker[order(var_ticker[,1], decreasing=FALSE),])
```

The crisis measure does not have a significant influence on the two sectors. Only inflation seems to have an influence on the other two measures.

### Closer Look into Consumer Discretionary Select Sector (XLY)


```{r, echo=FALSE}
# Possible control variable: Weekly economic index (https://fred.stlouisfed.org/series/WEI)
#install.packages("fredr")
library(fredr)
API_key = '2faca85963d14d8773a961ebdf748e15'

fredr_set_key(API_key)

fredr(
  series_id = "WEI",
  observation_start = as.Date("2021-12-01"),
  observation_end = as.Date("2023-12-01")
)

```



## 5. Conclusion


